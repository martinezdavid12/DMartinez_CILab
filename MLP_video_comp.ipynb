{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import PyTorch and matplotlib\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pthflops import count_ops\n",
    "\n",
    "vRead = iio.imread(\"c_elegans.mp4\")\n",
    "video = np.array(vRead)\n",
    "\n",
    "#Check PyTorch version\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n",
      "Is cuDNN version: 8302\n",
      "cuDNN enabled:  True\n",
      "Device count:  4\n",
      "Current device:  1\n",
      "Device name:  NVIDIA TITAN Xp\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "if(torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(\"cuda:1\")\n",
    "\n",
    "    print(\"Is cuDNN version:\", torch.backends.cudnn.version())\n",
    "\n",
    "    print(\"cuDNN enabled:a\", torch.backends.cudnn.enabled)\n",
    "\n",
    "    print(\"Device count: \", torch.cuda.device_count())\n",
    "\n",
    "    print(\"Current device: \", torch.cuda.current_device())\n",
    "\n",
    "    print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "#Setup device agnostic code (i.e use GPU if possible)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpuNum = 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (frames, w, h, RGB): \n",
      "(2484, 322, 344, 3)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#Video Metadata\n",
    "import imageio.v3 as iio\n",
    "props = iio.improps(\"c_elegans.mp4\")\n",
    "print(\"Shape (frames, w, h, RGB): \\n\" + str(props.shape))\n",
    "numFrames = props.shape[0]\n",
    "print(props.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Image as a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 322, 344, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input grid  (width_px, height_ px)\n",
    "grid = torch.empty(400, props.shape[1], props.shape[2], 3).to(device)\n",
    "\n",
    "print(numFrames)\n",
    "# Create image tensor\n",
    "videoIn = torch.as_tensor(video[:400])\n",
    "videoIn.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Max number of frames ---> numFrames   variable \n",
    "\n",
    "class SingleImageDataset(Dataset):\n",
    "    def __init__(self, videoIn, transform=None, target_transform=None):\n",
    "        self.videoIn = videoIn.type(torch.int32)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return int(image.shape[0]) * int(image.shape[1])\n",
    "    def __getitem__(self, idx):\n",
    "        row = idx // int(image.shape[1])\n",
    "        col = idx % int(image.shape[1])\n",
    "        #Generate random frame\n",
    "        frameLimit = videoIn.shape[0]\n",
    "        currFrame = torch.randint(0, frameLimit, (1,)).item()\n",
    "        pixel = torch.as_tensor(self.videoIn[currFrame][row][col]).type(torch.int32).cpu()\n",
    "        #label = pixel\n",
    "        return torch.as_tensor([currFrame, row, col]).cpu(), pixel\n",
    "training_data = SingleImageDataset(videoIn)\n",
    "#testing_data = None\n",
    "\n",
    "#train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "#train_dataloader = DataLoader(testing_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currFrame = torch.randint(0, 400, (1,)).item()\n",
    "currFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding video data from MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideoMP4(videoTensor, filename='decoded'):\n",
    "    w = iio.get_writer(filename + '.mp4', format='FFMPEG', mode='I', fps=20,\n",
    "                        codec='h264_vaapi',\n",
    "                        output_params=['-vaapi_device',\n",
    "                                        '/dev/dri/renderD128',\n",
    "                                        '-vf',\n",
    "                                        'format=gray|nv12,hwupload'],\n",
    "                        pixelformat='vaapi_vld')\n",
    "    for frame in videoTensor:\n",
    "        w.append_data(frame)\n",
    "    w.close()\n",
    "    print('video saved in local directory as: ' + filename + '.mp4')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideoGIF(videoTensor, filename='decoded'):\n",
    "    fps = 30\n",
    "    dur = 1000 * (1/fps)\n",
    "    iio.imwrite(filename + '.gif', videoTensor.cpu().numpy(), duration=dur)\n",
    "    print('video saved in local directory as: ' + filename + '.gif')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING THE VIDEO WRITER\n",
    "writeVideoGIF(videoIn, 'example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "#Use seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "#Multilayer Percepetron Model \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "        nn.Linear(input_shape, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, output_shape),\n",
    "        )\n",
    "    #forward reconstruction\n",
    "    def forward(self, X):\n",
    "        return self.layer_stack(X.to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an Instance and set loss function & optimizer\n",
    "model_0 = MLP(input_shape=3, \n",
    "              hidden_units=128, \n",
    "              output_shape=3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr1 = 0.00001\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                             lr=lr1)\n",
    "#list(model_0.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Loop:  NN --> Tensor --> GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to reconstruct image for some frame\n",
    "def test_loop():\n",
    "    model_0.eval()\n",
    "    testVideo = torch.zeros(videoIn.shape[0], videoIn.shape[1], videoIn.shape[2], 3).type(torch.int32)\n",
    "    with torch.inference_mode():\n",
    "        for i in range(0,10):\n",
    "            for j in range(0, testVideo.shape[1]):\n",
    "                for k in range(0, testVideo.shape[2]):\n",
    "                    testVideo[i][j][k] = model_0(torch.tensor([1.0 * i, 1.0 * j, 1.0 * k])).type(torch.float32)\n",
    "    writeVideoGIF(testVideo, 'reconstruction')\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_dataloader = DataLoader(videoIn, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "def trainLoop():\n",
    "  #Track values\n",
    "  #Loop through data\n",
    "  for epoch in tqdm(range(0, 100)):\n",
    "      ### Training\n",
    "      model_0.train()\n",
    "      #Process DataLoader Batch\n",
    "      for batch in iter(train_dataloader):\n",
    "        #print(\"new batch!\")\n",
    "        coords = torch.as_tensor(batch[0]).to(device)\n",
    "        pixels = torch.as_tensor(batch[1]).to(device)\n",
    "        #Loop through each pixel in batch\n",
    "        \n",
    "        X = torch.as_tensor(coords).type(torch.float32).to(device)\n",
    "        y_train = torch.as_tensor(pixels).type(torch.float32).to(device)\n",
    "        \n",
    "        #1. Forward Pass\n",
    "        y_pred = model_0(X).to(device)\n",
    "        #2. Calculate Loss\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        #3. Optimizer Zero Grad\n",
    "        optimizer.zero_grad()\n",
    "        #4. Backpropagation\n",
    "        loss.backward()\n",
    "        #5. Step optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "      if epoch % 2 == 0:\n",
    "        print(f\"Epoch: {epoch} | LR: {lr1} | Train loss: {loss}\")\n",
    "        #test_loop()\n",
    "\n",
    "  print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | LR: 0.0001 | Train loss: 908.991455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:01<00:43,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | LR: 0.0001 | Train loss: 1131.4500732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:02<00:48,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | LR: 0.0001 | Train loss: 897.8978271484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:03<00:46,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | LR: 0.0001 | Train loss: 1417.441162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:04<00:38,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | LR: 0.0001 | Train loss: 1140.005615234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:05<00:34,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | LR: 0.0001 | Train loss: 1327.69091796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:05<00:35,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | LR: 0.0001 | Train loss: 602.7757568359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:06<00:37,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | LR: 0.0001 | Train loss: 1128.7081298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:07<00:37,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | LR: 0.0001 | Train loss: 529.8741455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:08<00:34,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | LR: 0.0001 | Train loss: 1214.236572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:09<00:28,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | LR: 0.0001 | Train loss: 848.73779296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:09<00:26,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | LR: 0.0001 | Train loss: 1106.925537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:10<00:30,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | LR: 0.0001 | Train loss: 570.2239990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:11<00:26,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | LR: 0.0001 | Train loss: 1154.8629150390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:11<00:23,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | LR: 0.0001 | Train loss: 729.6185302734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:12<00:19,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | LR: 0.0001 | Train loss: 639.49658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:13<00:24,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | LR: 0.0001 | Train loss: 1104.499267578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:14<00:30,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | LR: 0.0001 | Train loss: 1011.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:15<00:30,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | LR: 0.0001 | Train loss: 943.2521362304688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:16<00:32,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | LR: 0.0001 | Train loss: 553.3683471679688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:17<00:30,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | LR: 0.0001 | Train loss: 1069.639404296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:18<00:21,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | LR: 0.0001 | Train loss: 1082.1944580078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:18<00:21,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | LR: 0.0001 | Train loss: 982.7536010742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:20<00:25,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | LR: 0.0001 | Train loss: 920.28759765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:21<00:24,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | LR: 0.0001 | Train loss: 861.734130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:21<00:19,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | LR: 0.0001 | Train loss: 422.4391174316406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:22<00:12,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | LR: 0.0001 | Train loss: 980.191162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:22<00:11,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 | LR: 0.0001 | Train loss: 1177.2655029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:23<00:11,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | LR: 0.0001 | Train loss: 962.544921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:23<00:11,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 | LR: 0.0001 | Train loss: 560.8472290039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:24<00:14,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | LR: 0.0001 | Train loss: 988.062255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:25<00:17,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | LR: 0.0001 | Train loss: 736.2259521484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:26<00:15,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 | LR: 0.0001 | Train loss: 1099.406982421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:27<00:14,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 | LR: 0.0001 | Train loss: 611.450927734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [00:28<00:15,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | LR: 0.0001 | Train loss: 888.4823608398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:29<00:13,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | LR: 0.0001 | Train loss: 1012.5055541992188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:30<00:10,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 | LR: 0.0001 | Train loss: 1361.6658935546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:30<00:09,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 | LR: 0.0001 | Train loss: 670.1310424804688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:31<00:09,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 | LR: 0.0001 | Train loss: 1105.3677978515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:32<00:10,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 | LR: 0.0001 | Train loss: 1380.021728515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:33<00:08,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | LR: 0.0001 | Train loss: 602.5861206054688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:34<00:07,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | LR: 0.0001 | Train loss: 936.5995483398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [00:35<00:08,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 | LR: 0.0001 | Train loss: 631.9671020507812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:36<00:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | LR: 0.0001 | Train loss: 340.1422424316406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:38<00:06,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 | LR: 0.0001 | Train loss: 802.0991821289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:39<00:05,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | LR: 0.0001 | Train loss: 776.5137939453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:40<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 | LR: 0.0001 | Train loss: 962.6312255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [00:41<00:02,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 | LR: 0.0001 | Train loss: 1402.83349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:42<00:01,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 | LR: 0.0001 | Train loss: 819.2588500976562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:43<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 | LR: 0.0001 | Train loss: 781.194580078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model State Dictionary\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"video_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "MODEL_SAVE_PATH\n",
    "\n",
    "#3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)\n",
    "print(MODEL_SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
    "#loaded_model_0 = MLP() # new instance!\n",
    "\n",
    "#Load the saved state_dict of model_0 (this wil updated the new instance with the updated parameters.)\n",
    "model_0.load_state_dict(torch.load(f='models/video_model_0.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Raw Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model size by summing parameters and state_dict\n",
    "params_size = 0\n",
    "for param in model_0.parameters():\n",
    "    params_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model_0.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (params_size + buffer_size) / 1024**2\n",
    "videoSize = videoIn.shape[0] * (8 * videoIn.shape[1] * videoIn.shape[2] * 3)\n",
    "videoSizeMB = videoSize / (10**6)\n",
    "perDecrease = (videoSizeMB - size_all_mb) / videoSizeMB\n",
    "perDecrease *= 100\n",
    "print('original image size(no compression): {:.3f}MB'.format(videoSizeMB))\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "print('Percent decrease in memory size: {:.3f}%'.format(perDecrease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kill Kernel\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d545b3ac37ec0154d84c1a82ee00c1956fba906fce684ac0bc9af096a3e98d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
