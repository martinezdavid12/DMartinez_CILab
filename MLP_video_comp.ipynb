{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import PyTorch and matplotlib\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pthflops import count_ops\n",
    "\n",
    "vRead = iio.imread(\"c_elegans.mp4\")\n",
    "video = np.array(vRead)\n",
    "\n",
    "#Check PyTorch version\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "if(torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(\"cuda:3\")\n",
    "\n",
    "    print(\"Is cuDNN version:\", torch.backends.cudnn.version())\n",
    "\n",
    "    print(\"cuDNN enabled: \", torch.backends.cudnn.enabled)\n",
    "\n",
    "    print(\"Device count: \", torch.cuda.device_count())\n",
    "\n",
    "    print(\"Current device: \", torch.cuda.current_device())\n",
    "\n",
    "    print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "#Setup device agnostic code (i.e use GPU if possible)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpuNum = 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (frames, w, h, RGB): \n",
      "(2484, 322, 344, 3)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#Video Metadata\n",
    "import imageio.v3 as iio\n",
    "props = iio.improps(\"c_elegans.mp4\")\n",
    "print(\"Shape (frames, w, h, RGB): \\n\" + str(props.shape))\n",
    "print(props.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Image as a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input grid  (width_px, height_ px)\n",
    "grid = torch.empty(props.shape[1], props.shape[2], 3).to(device)\n",
    "\n",
    "# Create image tensor\n",
    "frame = 0\n",
    "image = torch.tensor(video[frame]).to(device)\n",
    "image = image.type(torch.int32)\n",
    "\n",
    "image.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/47/kdzqfc9j7csfgrbl6qstjc780000gn/T/ipykernel_82366/789721602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#label = pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#testing_data = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SingleImageDataset(Dataset):\n",
    "    def __init__(self, image, transform=None, target_transform=None):\n",
    "        self.image = image.type(torch.int32)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return int(image.shape[0]) * int(image.shape[1])\n",
    "    def __getitem__(self, idx):\n",
    "        row = idx // int(image.shape[1])\n",
    "        col = idx % int(image.shape[1])\n",
    "        pixel = torch.as_tensor(self.image[row][col]).type(torch.int32).cpu()\n",
    "        #label = pixel\n",
    "        return torch.as_tensor([row, col]).cpu(), pixel\n",
    "training_data = SingleImageDataset(image)\n",
    "#testing_data = None\n",
    "\n",
    "#train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "#train_dataloader = DataLoader(testing_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07a481119aadb6992ff0da222930d2b0a8a26de193018adba40c1ff699702765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
