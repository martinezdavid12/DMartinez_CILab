{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PyTorch and matplotlib\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pthflops import count_ops\n",
    "\n",
    "vRead = iio.imread(\"c_elegans.mp4\")\n",
    "video = np.array(vRead)\n",
    "\n",
    "#Check PyTorch version\n",
    "torch.__version__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET GPU if possible\n",
    "run in shell: \n",
    "CUDA_VISIBLE_DEVICES= {gpu#/#s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Is cuDNN version:\", torch.backends.cudnn.version())\n",
    "\n",
    "print(\"cuDNN enabled: \", torch.backends.cudnn.enabled)\n",
    "\n",
    "print(\"Device count: \", torch.cuda.device_count())\n",
    "\n",
    "print(\"Current device: \", torch.cuda.current_device())\n",
    "\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "#Setup device agnostic code (i.e use GPU if possible)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpuNum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Metadata\n",
    "import imageio.v3 as iio\n",
    "props = iio.improps(\"c_elegans.mp4\")\n",
    "print(\"Shape (frames, w, h, RGB): \\n\" + str(props.shape))\n",
    "print(props.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding image data as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input grid  (frame, width_px, height_ px)\n",
    "grid = torch.empty(props.shape[0], props.shape[1], props.shape[2]).to(device)\n",
    "\n",
    "# Create video tensor\n",
    "npVideo = video\n",
    "video = torch.tensor(video, dtype=torch.int32).to(device)\n",
    "print(video.dtype)\n",
    "\n",
    "#Generate input and output vectors for training and testing\n",
    "temp = video.clone()\n",
    "X = temp.squeeze(dim=1)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFrame = 10\n",
    "plt.imshow(video[testFrame].cpu())\n",
    "plt.axis(False)\n",
    "plt.title(\"Frame: \" + str(testFrame));\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Model (MLP-based Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "#Use seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "#Multilayer Percepetron Model \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "        nn.Linear(input_shape, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_units, output_shape),\n",
    "        )\n",
    "    #forward reconstruction\n",
    "    def forward(self, X):\n",
    "        return self.layer_stack(X.to(device))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an Instance and set loss function & optimizer\n",
    "model_0 = MLP(input_shape=3, \n",
    "              hidden_units=32, \n",
    "              output_shape=3).to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                             lr=0.001)\n",
    "#list(model_0.parameters())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def trainLoop():\n",
    "  #Track values\n",
    "  epoch_count = []\n",
    "  loss_values = []\n",
    "  test_loss_values = []\n",
    "  #Loop through data\n",
    "  for epoch in range(0, 5):\n",
    "      epoch_count.append(epoch)\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "      # Set Model to training mode\n",
    "      model_0.train()\n",
    "\n",
    "      for frame in range(0, len(grid)):\n",
    "         for row in range(0, len(grid[0])):\n",
    "            for col in range(0, len(grid[0][0])):\n",
    "              ###Coordinate Training\n",
    "              #Forward Pass\n",
    "              X = torch.tensor([[frame * 1.0, row * 1.0, col * 1.0]], dtype=torch.float32).to(device)\n",
    "              pred = torch.round(model_0(X.unsqueeze(dim=1).to(device))).to(device)\n",
    "              # Compute loss (training)\n",
    "              #print(video[frame][row][col])\n",
    "              loss = loss_fn(pred, torch.tensor(video[frame][row][col].to(device), dtype=torch.float32).to(device))\n",
    "              #print(pred, loss)\n",
    "              # Zero the gradients\n",
    "              optimizer.zero_grad()\n",
    "              # Perform backpropagation on loss with respect to params\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "      \n",
    "      #Stat things\n",
    "      if(epoch % 10 == 0):\n",
    "          epoch_count.append(epoch)\n",
    "          loss_values.append(loss)\n",
    "          #test_loss_values.append(test_loss)\n",
    "          print(f\"Epoch {epoch} | Loss: {loss} | Test loss: \")\n",
    "          # Print out the model state_dict()\n",
    "          print(model_0.state_dict())\n",
    "\n",
    "  print('Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainLoop()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to reconstruct image for some frame\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    frame = 0\n",
    "    results = torch.zeros(len(grid[0]), len(grid[0][0]), 3)\n",
    "    for row in range(0, len(grid[0])):\n",
    "        for col in range(0, len(grid[0][0])):\n",
    "            T = torch.tensor([[frame, row, col]], dtype=torch.float32).to(device)\n",
    "            results[row][col] = torch.round(model_0(T.squeeze(dim=1))).to(device)\n",
    "    plt.imshow(results.cpu())\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07a481119aadb6992ff0da222930d2b0a8a26de193018adba40c1ff699702765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
